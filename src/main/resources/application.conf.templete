
akka {
  jvm-exit-on-fatal-error = true
    loggers = ["akka.event.slf4j.Slf4jLogger","com.neighborhood.aka.laplace.estuary.core.akkaUtil.EstuaryEventListener"]
  loglevel = "INFO"
//    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  stdout-loglevel = "OFF"

  pinned-dispatcher {
    # Dispatcher 是基于事件的派发器的名称
    type = PinnedDispatcher
  }

  batcher-dispatcher {
    # Dispatcher is the name of the event-based dispatcher
    type = Dispatcher
    # What kind of ExecutionService to use
    executor = "fork-join-executor"
    # Configuration for the fork join pool
    fork-join-executor {
      # Min number of threads to cap factor-based parallelism number to
      parallelism-min = 2
      # Parallelism (threads) ... ceil(available processors * factor)
      parallelism-factor = 2.0
      # Max number of threads to cap factor-based parallelism number to
      parallelism-max = 12
    }
    # Throughput defines the maximum number of messages to be
    # processed per actor before the thread jumps to the next actor.
    # Set to 1 for as fair as possible.
    throughput = 50
  }

  kafka.producer {
    # Tuning parameter of how many sends that can run in parallel.
    parallelism = 100

    # How long to wait for `KafkaProducer.close`
    close-timeout = 30s

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the producer stages. Some blocking may occur.
    # When this value is empty, the dispatcher configured for the stream
    # will be used.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.producer.ProducerConfig
    # can be defined in this configuration section.
    kafka-clients {

    }
  }

}
mongodb{
  url="mongodb://admin:instrum@localhost:27017/?authSource=admin&authMechanism=SCRAM-SHA-1"
  dbName="testAdmin"
}
error.monitor{
   url=""
   mobiles=""
}










